{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyObOY8Qa9bKTOBmaOvNjkC9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahendren84/CS6886W_CS24M523_A1/blob/main/CS6886W_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxH2xWtmLvic",
        "outputId": "27cc23a8-62ab-4d26-81f7-9057394a53b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CS6886W_CS24M523_A1' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mahendren84/CS6886W_CS24M523_A1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaiBzYzaflFK",
        "outputId": "5fa9d2b9-342f-47e8-8b7a-3e334e4a4f37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 0s (159 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 126718 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tree  /content/CS6886W_CS24M523_A1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HhZsa7SfT1a",
        "outputId": "caf6dead-fa07-4bb1-a8b1-a18cfa507042"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m/content/CS6886W_CS24M523_A1\u001b[0m\n",
            "├── \u001b[00mCS6886W_Assignment1.ipynb\u001b[0m\n",
            "├── \u001b[00mDataModel.py\u001b[0m\n",
            "├── \u001b[00mMakePlots.py\u001b[0m\n",
            "├── \u001b[00mModel.py\u001b[0m\n",
            "├── \u001b[00mpatch_amp.py\u001b[0m\n",
            "├── \u001b[00mrequirements.txt\u001b[0m\n",
            "├── \u001b[01;34mscripts\u001b[0m\n",
            "│   ├── \u001b[00mmake_plots.sh\u001b[0m\n",
            "│   ├── \u001b[00mrun_baseline.sh\u001b[0m\n",
            "│   ├── \u001b[00mrun_sweep_full.sh\u001b[0m\n",
            "│   ├── \u001b[00mrun_sweep_quick.sh\u001b[0m\n",
            "│   └── \u001b[00mtest_model.sh\u001b[0m\n",
            "├── \u001b[00msweep_full.yaml\u001b[0m\n",
            "├── \u001b[00msweep_quick.yaml\u001b[0m\n",
            "├── \u001b[00mTest.py\u001b[0m\n",
            "└── \u001b[00mTrain.py\u001b[0m\n",
            "\n",
            "1 directory, 15 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb; wandb.login()  # follow the link, paste your API key\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2s0Afytf0hj",
        "outputId": "f7cd7444-4ae6-4fb2-adb6-6b51679676fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CS6886W_CS24M523_A1\n",
        "!pip install torch torchvision tqdm wandb numpy rich pandas matplotlib\n",
        "!chmod +x scripts/*.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK7_r6bqgY1b",
        "outputId": "2ef061e3-e2c8-4007-a807-432f0c2ab24f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CS6886W_CS24M523_A1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (13.9.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.42.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich) (2.19.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb sweep sweep_quick.yaml\n",
        "# copy the printed path, then run exactly 20 trials:\n",
        "#!wandb agent --count 20 mahee-velu-iitm/cs6886-vgg6-cifar10/sweeps/e7k5tpnp\n",
        "!wandb agent --count 20 mahee-velu-iitm/sweep-quick/3uq71bnp\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-m-Zds0gZBS",
        "outputId": "2044f19c-d320-4848-d0b0-b7952634ae71"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep from: sweep_quick.yaml\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Couldn't open sweep file: sweep_quick.yaml\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/wandb\", line 10, in <module>\n",
            "    sys.exit(cli())\n",
            "             ^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1462, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1383, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1850, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1246, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 814, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/decorators.py\", line 34, in new_func\n",
            "    return f(get_current_context(), *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/wandb/cli/cli.py\", line 137, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/wandb/cli/cli.py\", line 913, in sweep\n",
            "    is_local = config.get(\"controller\", {}).get(\"type\") == \"local\"\n",
            "               ^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'get'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash scripts/run_baseline.sh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdWAMPj2M1yF",
        "outputId": "c16f208b-daec-4a07-8146-002caf718491"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_082107-etw9lyzx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcosmic-pond-12\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/cs6886-vgg6-cifar10\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/cs6886-vgg6-cifar10/runs/etw9lyzx\u001b[0m\n",
            "100% 170M/170M [00:04<00:00, 41.1MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CS6886W_CS24M523_A1/Train.py\", line 169, in <module>\n",
            "    main()\n",
            "  File \"/content/CS6886W_CS24M523_A1/Train.py\", line 95, in main\n",
            "    train_loader, val_loader, test_loader = get_dataloaders(\n",
            "                                            ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/CS6886W_CS24M523_A1/DataModel.py\", line 23, in get_dataloaders\n",
            "    train_full = datasets.CIFAR10(root=data_root, train=True,  download=True, transform=train_tfms)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/datasets/cifar.py\", line 66, in __init__\n",
            "    self.download()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/datasets/cifar.py\", line 139, in download\n",
            "    download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.tgz_md5)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/datasets/utils.py\", line 391, in download_and_extract_archive\n",
            "    extract_archive(archive, extract_root, remove_finished)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/datasets/utils.py\", line 367, in extract_archive\n",
            "    extractor(from_path, to_path, compression)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torchvision/datasets/utils.py\", line 213, in _extract_tar\n",
            "    tar.extractall(to_path)\n",
            "  File \"/usr/lib/python3.12/tarfile.py\", line 2323, in extractall\n",
            "    self._extract_one(tarinfo, path, set_attrs=not tarinfo.isdir(),\n",
            "  File \"/usr/lib/python3.12/tarfile.py\", line 2426, in _extract_one\n",
            "    self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n",
            "  File \"/usr/lib/python3.12/tarfile.py\", line 2515, in _extract_member\n",
            "    self.makefile(tarinfo, targetpath)\n",
            "  File \"/usr/lib/python3.12/tarfile.py\", line 2572, in makefile\n",
            "    copyfileobj(source, target, tarinfo.size, ReadError, bufsize)\n",
            "  File \"/usr/lib/python3.12/tarfile.py\", line 251, in copyfileobj\n",
            "    buf = src.read(bufsize)\n",
            "          ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/gzip.py\", line 338, in read\n",
            "    return self._buffer.read(size)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/_compression.py\", line 68, in readinto\n",
            "    data = self.read(len(byte_view))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/gzip.py\", line 567, in read\n",
            "    self._crc = zlib.crc32(uncompress, self._crc)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mcosmic-pond-12\u001b[0m at: \u001b[34m\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251025_082107-etw9lyzx/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb sweep sweep_full.yaml\n",
        "# copy the printed path, then run exactly 25 trials:\n",
        "!wandb agent --count 25 mahee-velu-iitm/sweep-full/efhuc9f6\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g738NIzrKN3d",
        "outputId": "2916974c-57c3-48ba-8ce0-2cda9d9a85a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep from: sweep_full.yaml\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep with ID: \u001b[33m6zfe6z8g\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: View sweep at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/cs6886-vgg6-cifar10/sweeps/6zfe6z8g\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run sweep agent with: \u001b[33mwandb agent mahee-velu-iitm/cs6886-vgg6-cifar10/6zfe6z8g\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
            "2025-10-25 08:21:31,212 - wandb.wandb_agent - INFO - Running runs: []\n",
            "2025-10-25 08:21:31,709 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 08:21:31,709 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: tanh\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 256\n",
            "\tepochs: 50\n",
            "\tlr: 0.018977151633370888\n",
            "\toptimizer: adagrad\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 9.901735848609784e-05\n",
            "2025-10-25 08:21:31,711 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=tanh --autoaugment=True --batch_size=256 --epochs=50 --lr=0.018977151633370888 --optimizer=adagrad --scheduler=cosine --seed=42 --weight_decay=9.901735848609784e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_082135-d0x0q44y\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mancient-sweep-13\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/d0x0q44y\u001b[0m\n",
            "2025-10-25 08:21:36,717 - wandb.wandb_agent - INFO - Running runs: ['d0x0q44y']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/50:   0% 0/176 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/50:  57% 100/176 [00:11<00:13,  5.59it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.8094\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_8801_eb89233bd9ccfed6e7c...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_8801_eb89233bd9ccfed6e7c...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_8801_eb89233bd9ccfed6e7c...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_8801_eb89233bd9ccfed6e7c...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_8801_eb89233bd9ccfed6e7c...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_8801_eb89233bd9ccfed6e7c...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_8801_eb89233bd9ccfed6e7c...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_8801_eb89233bd9ccfed6e7c...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_8801_eb89233bd9ccfed6e7c...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-d0x0q44y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ██████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▂▃▃▄▅▄▅▅▅▆▆▆▆▇▇▆▆▇▇▇▇▇▇███████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▇▆▆▅▅▄▄▃▃▃▃▃▃▂▂▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▂▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▆▆▇▇▇▇▇▇███████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.8094\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.54366\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.75753\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.69692\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.7454\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.72662\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mancient-sweep-13\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/d0x0q44y\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_082135-d0x0q44y/logs\u001b[0m\n",
            "2025-10-25 08:51:53,169 - wandb.wandb_agent - INFO - Cleaning up finished run: d0x0q44y\n",
            "2025-10-25 08:51:53,504 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 08:51:53,504 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: relu\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 256\n",
            "\tepochs: 100\n",
            "\tlr: 0.0029028601438789103\n",
            "\toptimizer: nadam\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.00017666315289511988\n",
            "2025-10-25 08:51:53,506 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=relu --autoaugment=True --batch_size=256 --epochs=100 --lr=0.0029028601438789103 --optimizer=nadam --scheduler=cosine --seed=42 --weight_decay=0.00017666315289511988\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_085157-kepxau5y\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlyric-sweep-14\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/kepxau5y\u001b[0m\n",
            "2025-10-25 08:51:58,512 - wandb.wandb_agent - INFO - Running runs: ['kepxau5y']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/100:   0% 0/176 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100:  57% 100/176 [00:10<00:12,  6.28it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.9258\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e3c7c9cc2c95ecab95...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e3c7c9cc2c95ecab95...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e3c7c9cc2c95ecab95...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e3c7c9cc2c95ecab95...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e3c7c9cc2c95ecab95...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e3c7c9cc2c95ecab95...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e3c7c9cc2c95ecab95...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e3c7c9cc2c95ecab95...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e3c7c9cc2c95ecab95...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-kepxau5y-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ██████████▇▇▇▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▁▃▄▃▅▄▄▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ██▆▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▂▆▆▆▅▆▆▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▆▆▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.9258\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.2528\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.93856\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.17845\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.8818\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.3689\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlyric-sweep-14\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/kepxau5y\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_085157-kepxau5y/logs\u001b[0m\n",
            "2025-10-25 09:52:26,735 - wandb.wandb_agent - INFO - Cleaning up finished run: kepxau5y\n",
            "2025-10-25 09:52:26,877 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 09:52:26,877 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: gelu\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 256\n",
            "\tepochs: 50\n",
            "\tlr: 0.04842141455755715\n",
            "\toptimizer: adagrad\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.00011436249950424272\n",
            "2025-10-25 09:52:26,878 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=gelu --autoaugment=True --batch_size=256 --epochs=50 --lr=0.04842141455755715 --optimizer=adagrad --scheduler=cosine --seed=42 --weight_decay=0.00011436249950424272\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_095230-jrxs10uq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrisp-sweep-10\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/jrxs10uq\u001b[0m\n",
            "2025-10-25 09:52:31,885 - wandb.wandb_agent - INFO - Running runs: ['jrxs10uq']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/50:   0% 0/176 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/50:  57% 100/176 [00:10<00:11,  6.46it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.7488\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-jrxs10uq-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_8801_946a277708a92bd0fd1...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-jrxs10uq-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_8801_946a277708a92bd0fd1...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-jrxs10uq-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_8801_946a277708a92bd0fd1...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-jrxs10uq-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_8801_946a277708a92bd0fd1...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-jrxs10uq-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_8801_946a277708a92bd0fd1...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-jrxs10uq-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_8801_946a277708a92bd0fd1...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-jrxs10uq-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_8801_946a277708a92bd0fd1...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-jrxs10uq-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_8801_946a277708a92bd0fd1...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-jrxs10uq-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_8801_946a277708a92bd0fd1...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ███████▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ██▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ██▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.7488\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.70973\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.67462\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.92792\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.673\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.92918\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcrisp-sweep-10\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/jrxs10uq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_095230-jrxs10uq/logs\u001b[0m\n",
            "2025-10-25 10:22:42,873 - wandb.wandb_agent - INFO - Cleaning up finished run: jrxs10uq\n",
            "2025-10-25 10:22:43,021 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 10:22:43,021 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: relu\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 256\n",
            "\tepochs: 10\n",
            "\tlr: 0.004629706632739081\n",
            "\toptimizer: adagrad\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.00015702419829318476\n",
            "2025-10-25 10:22:43,022 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=relu --autoaugment=True --batch_size=256 --epochs=10 --lr=0.004629706632739081 --optimizer=adagrad --scheduler=cosine --seed=42 --weight_decay=0.00015702419829318476\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_102246-hqhgoolx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlikely-sweep-11\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/hqhgoolx\u001b[0m\n",
            "2025-10-25 10:22:48,028 - wandb.wandb_agent - INFO - Running runs: ['hqhgoolx']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/10:   0% 0/176 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/10:  57% 100/176 [00:10<00:12,  6.16it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.6816\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-hqhgoolx-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_1761_92382d71f45fc7d9efe...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-hqhgoolx-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_1761_92382d71f45fc7d9efe...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-hqhgoolx-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_1761_92382d71f45fc7d9efe...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-hqhgoolx-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_1761_92382d71f45fc7d9efe...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-hqhgoolx-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_1761_92382d71f45fc7d9efe...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-hqhgoolx-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_1761_92382d71f45fc7d9efe...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-hqhgoolx-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_1761_92382d71f45fc7d9efe...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-hqhgoolx-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_1761_92382d71f45fc7d9efe...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-hqhgoolx-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_1761_92382d71f45fc7d9efe...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr █▇▇▆▅▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▃▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▆▄▃▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.6816\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.88511\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.605\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 1.10384\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.6006\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.12005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlikely-sweep-11\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/hqhgoolx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_102246-hqhgoolx/logs\u001b[0m\n",
            "2025-10-25 10:28:58,378 - wandb.wandb_agent - INFO - Cleaning up finished run: hqhgoolx\n",
            "2025-10-25 10:28:58,515 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 10:28:58,515 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: sigmoid\n",
            "\tautoaugment: False\n",
            "\tbatch_size: 128\n",
            "\tepochs: 100\n",
            "\tlr: 0.0007284308049922777\n",
            "\toptimizer: sgd_nesterov\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 1.0223185744025394e-05\n",
            "2025-10-25 10:28:58,516 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=sigmoid --autoaugment=False --batch_size=128 --epochs=100 --lr=0.0007284308049922777 --optimizer=sgd_nesterov --scheduler=cosine --seed=42 --weight_decay=1.0223185744025394e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_102902-jq8frpor\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpolar-sweep-12\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/jq8frpor\u001b[0m\n",
            "2025-10-25 10:29:03,522 - wandb.wandb_agent - INFO - Running runs: ['jq8frpor']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/100:   0% 0/352 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100:  28% 100/352 [00:04<00:15, 16.06it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.7303\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-jq8frpor-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_89c80f12b75bce9d77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-jq8frpor-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_35201_89c80f12b75bce9d77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-jq8frpor-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_35201_89c80f12b75bce9d77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-jq8frpor-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_35201_89c80f12b75bce9d77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-jq8frpor-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_35201_89c80f12b75bce9d77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-jq8frpor-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_35201_89c80f12b75bce9d77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-jq8frpor-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_35201_89c80f12b75bce9d77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-jq8frpor-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_89c80f12b75bce9d77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-jq8frpor-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_89c80f12b75bce9d77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ██████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▂▃▃▄▅▄▃▅▅▄▅▆▅▄▆▅▆▆▇▆▇▅▆▇▆▇▇▇▇█▇███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ▆▆▆█▇▅▄▄▄▃█▆▆▄▄▅▄▂▄▄▃▅▆▃▃▂▂▁▄▃▂▁▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▂▂▁▂▁▃▃▅▃▂▂▃▅▅▄▃▅▃▅▃▄▄▆▇▆▇▇▆▆▇▇█████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ▄▄▃▄▃▃▃▄▄▂▃▄█▂▂▃▂▄▂▂▂▁▁▃▂▁▁▂▁▂▁▁▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.7303\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.7532\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.7158\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.79536\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.6964\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.8479\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mpolar-sweep-12\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/jq8frpor\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_102902-jq8frpor/logs\u001b[0m\n",
            "2025-10-25 11:07:41,755 - wandb.wandb_agent - INFO - Cleaning up finished run: jq8frpor\n",
            "2025-10-25 11:07:42,119 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 11:07:42,119 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: tanh\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 64\n",
            "\tepochs: 50\n",
            "\tlr: 0.0026830069662843346\n",
            "\toptimizer: adam\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 4.58986516181456e-05\n",
            "2025-10-25 11:07:42,120 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=tanh --autoaugment=True --batch_size=64 --epochs=50 --lr=0.0026830069662843346 --optimizer=adam --scheduler=cosine --seed=42 --weight_decay=4.58986516181456e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_110746-str62b6n\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdesert-sweep-15\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/str62b6n\u001b[0m\n",
            "2025-10-25 11:07:47,126 - wandb.wandb_agent - INFO - Running runs: ['str62b6n']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/50:   0% 0/704 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/50:  14% 99/704 [00:03<00:16, 37.31it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.8650\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_9ed2cabc525af79510...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_35201_9ed2cabc525af79510...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_35201_9ed2cabc525af79510...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_35201_9ed2cabc525af79510...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_35201_9ed2cabc525af79510...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_35201_9ed2cabc525af79510...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_35201_9ed2cabc525af79510...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_9ed2cabc525af79510...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_9ed2cabc525af79510...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-str62b6n-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ██████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▁▂▃▃▃▃▄▄▄▄▅▅▅▅▆▅▆▆▆▇▆▆▇▇▇▇▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ▆█▆▆▆▅▅▅▄▅▄▄▄▄▄▃▃▃▂▃▃▂▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▂▁▂▃▃▃▃▄▄▄▅▄▅▅▆▆▅▆▆▆▆▇▆▇▇▇▇▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ▆█▆▆▆▅▅▅▄▄▄▄▃▄▃▃▂▃▃▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.865\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.40103\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.83131\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.4894\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.7978\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.56894\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdesert-sweep-15\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/str62b6n\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_110746-str62b6n/logs\u001b[0m\n",
            "2025-10-25 11:39:14,800 - wandb.wandb_agent - INFO - Cleaning up finished run: str62b6n\n",
            "2025-10-25 11:39:15,169 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 11:39:15,169 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: gelu\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 64\n",
            "\tepochs: 50\n",
            "\tlr: 0.002877539533684156\n",
            "\toptimizer: adagrad\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.00011984647818891578\n",
            "2025-10-25 11:39:15,171 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=gelu --autoaugment=True --batch_size=64 --epochs=50 --lr=0.002877539533684156 --optimizer=adagrad --scheduler=cosine --seed=42 --weight_decay=0.00011984647818891578\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_113919-lhwhutlf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mleafy-sweep-16\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/lhwhutlf\u001b[0m\n",
            "2025-10-25 11:39:20,177 - wandb.wandb_agent - INFO - Running runs: ['lhwhutlf']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/50:   0% 0/704 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/50:  14% 99/704 [00:03<00:14, 41.34it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.8666\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_545a0b62da3960446d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_35201_545a0b62da3960446d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_35201_545a0b62da3960446d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_35201_545a0b62da3960446d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_35201_545a0b62da3960446d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_35201_545a0b62da3960446d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_35201_545a0b62da3960446d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_545a0b62da3960446d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_545a0b62da3960446d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-lhwhutlf-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▅▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▂▄▄▅▇▆▆▆▇▇▇▇▇▇▇█▇█▇████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▇▅▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.8666\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.38002\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.83136\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.48723\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.8026\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.56343\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mleafy-sweep-16\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/lhwhutlf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_113919-lhwhutlf/logs\u001b[0m\n",
            "2025-10-25 12:10:42,994 - wandb.wandb_agent - INFO - Cleaning up finished run: lhwhutlf\n",
            "2025-10-25 12:10:43,464 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 12:10:43,465 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: gelu\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 128\n",
            "\tepochs: 50\n",
            "\tlr: 0.0005926452806078292\n",
            "\toptimizer: adagrad\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.00022661006158002157\n",
            "2025-10-25 12:10:43,466 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=gelu --autoaugment=True --batch_size=128 --epochs=50 --lr=0.0005926452806078292 --optimizer=adagrad --scheduler=cosine --seed=42 --weight_decay=0.00022661006158002157\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_121047-jrdg3hu6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msuper-sweep-17\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/jrdg3hu6\u001b[0m\n",
            "2025-10-25 12:10:48,472 - wandb.wandb_agent - INFO - Running runs: ['jrdg3hu6']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/50:   0% 0/352 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/50:  28% 99/352 [00:05<00:13, 19.25it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.7768\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-jrdg3hu6-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_17601_2db12dc1595234ad0a...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-jrdg3hu6-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_17601_2db12dc1595234ad0a...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-jrdg3hu6-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_17601_2db12dc1595234ad0a...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-jrdg3hu6-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_17601_2db12dc1595234ad0a...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-jrdg3hu6-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_17601_2db12dc1595234ad0a...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-jrdg3hu6-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_17601_2db12dc1595234ad0a...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-jrdg3hu6-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_17601_2db12dc1595234ad0a...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-jrdg3hu6-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_17601_2db12dc1595234ad0a...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-jrdg3hu6-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_17601_2db12dc1595234ad0a...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ██████▇▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇███████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇██████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.7768\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.63766\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.6956\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.8661\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.6928\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.86853\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msuper-sweep-17\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/jrdg3hu6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_121047-jrdg3hu6/logs\u001b[0m\n",
            "2025-10-25 12:41:45,702 - wandb.wandb_agent - INFO - Cleaning up finished run: jrdg3hu6\n",
            "2025-10-25 12:41:46,140 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 12:41:46,140 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: gelu\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 64\n",
            "\tepochs: 50\n",
            "\tlr: 0.002418931759247155\n",
            "\toptimizer: adam\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.00010944263368751324\n",
            "2025-10-25 12:41:46,141 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=gelu --autoaugment=True --batch_size=64 --epochs=50 --lr=0.002418931759247155 --optimizer=adam --scheduler=cosine --seed=42 --weight_decay=0.00010944263368751324\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_124150-ddzl5v2m\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdevout-sweep-18\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/ddzl5v2m\u001b[0m\n",
            "2025-10-25 12:41:51,147 - wandb.wandb_agent - INFO - Running runs: ['ddzl5v2m']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/50:   0% 0/704 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/50:  14% 99/704 [00:03<00:15, 38.65it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.9091\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-ddzl5v2m-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_fd4f5f9f03fd2e1516...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-ddzl5v2m-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_35201_fd4f5f9f03fd2e1516...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-ddzl5v2m-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_35201_fd4f5f9f03fd2e1516...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-ddzl5v2m-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_35201_fd4f5f9f03fd2e1516...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-ddzl5v2m-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_35201_fd4f5f9f03fd2e1516...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-ddzl5v2m-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_35201_fd4f5f9f03fd2e1516...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-ddzl5v2m-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_35201_fd4f5f9f03fd2e1516...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-ddzl5v2m-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_fd4f5f9f03fd2e1516...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-ddzl5v2m-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_fd4f5f9f03fd2e1516...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ███████▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▃▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▆▅▅▄▄▃▃▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▃▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▇▆▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.9091\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.28225\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.89847\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.29498\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.8548\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.43287\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdevout-sweep-18\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/ddzl5v2m\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_124150-ddzl5v2m/logs\u001b[0m\n",
            "2025-10-25 13:13:08,600 - wandb.wandb_agent - INFO - Cleaning up finished run: ddzl5v2m\n",
            "2025-10-25 13:13:09,053 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 13:13:09,053 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: gelu\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 128\n",
            "\tepochs: 100\n",
            "\tlr: 0.19362154697857065\n",
            "\toptimizer: sgd\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 5.9198847552808486e-05\n",
            "2025-10-25 13:13:09,054 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=gelu --autoaugment=True --batch_size=128 --epochs=100 --lr=0.19362154697857065 --optimizer=sgd --scheduler=cosine --seed=42 --weight_decay=5.9198847552808486e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_131313-3c93rc5i\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mefficient-sweep-19\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/3c93rc5i\u001b[0m\n",
            "2025-10-25 13:13:14,060 - wandb.wandb_agent - INFO - Running runs: ['3c93rc5i']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/100:   0% 0/352 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100:  28% 98/352 [00:05<00:12, 20.72it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.9278\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-3c93rc5i-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_30289bb7530b664cae...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-3c93rc5i-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_35201_30289bb7530b664cae...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-3c93rc5i-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_35201_30289bb7530b664cae...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-3c93rc5i-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_35201_30289bb7530b664cae...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-3c93rc5i-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_35201_30289bb7530b664cae...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-3c93rc5i-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_35201_30289bb7530b664cae...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-3c93rc5i-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_35201_30289bb7530b664cae...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-3c93rc5i-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_30289bb7530b664cae...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-3c93rc5i-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_30289bb7530b664cae...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ███████▇▇▇▆▆▆▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▄▄▅▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▆▅▄▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▂▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ██▇▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.9278\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.22886\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.9506\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.14752\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.8888\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.34634\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mefficient-sweep-19\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/3c93rc5i\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_131313-3c93rc5i/logs\u001b[0m\n",
            "2025-10-25 14:14:15,668 - wandb.wandb_agent - INFO - Cleaning up finished run: 3c93rc5i\n",
            "2025-10-25 14:14:16,177 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 14:14:16,177 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: silu\n",
            "\tautoaugment: False\n",
            "\tbatch_size: 64\n",
            "\tepochs: 100\n",
            "\tlr: 0.16598232657274928\n",
            "\toptimizer: sgd_nesterov\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.00020344511976600743\n",
            "2025-10-25 14:14:16,178 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=silu --autoaugment=False --batch_size=64 --epochs=100 --lr=0.16598232657274928 --optimizer=sgd_nesterov --scheduler=cosine --seed=42 --weight_decay=0.00020344511976600743\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_141420-km95xqdo\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myouthful-sweep-20\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/km95xqdo\u001b[0m\n",
            "2025-10-25 14:14:21,184 - wandb.wandb_agent - INFO - Running runs: ['km95xqdo']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/100:   0% 0/704 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100:  14% 99/704 [00:02<00:10, 56.61it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.9159\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_70401_746d4bf02b4cebcf05...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_70401_746d4bf02b4cebcf05...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_70401_746d4bf02b4cebcf05...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_70401_746d4bf02b4cebcf05...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_70401_746d4bf02b4cebcf05...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_70401_746d4bf02b4cebcf05...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_70401_746d4bf02b4cebcf05...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_70401_746d4bf02b4cebcf05...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_70401_746d4bf02b4cebcf05...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-km95xqdo-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ██████▇▇▇▇▇▇▇▆▆▆▆▆▆▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▃▃▄▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▆▅▆▆▇▇▇▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▇▆▆▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▆▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.9159\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.26394\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.96596\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.10467\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.29605\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33myouthful-sweep-20\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/km95xqdo\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_141420-km95xqdo/logs\u001b[0m\n",
            "2025-10-25 14:54:21,274 - wandb.wandb_agent - INFO - Cleaning up finished run: km95xqdo\n",
            "2025-10-25 14:54:21,645 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 14:54:21,645 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: tanh\n",
            "\tautoaugment: False\n",
            "\tbatch_size: 128\n",
            "\tepochs: 100\n",
            "\tlr: 0.11337537084409292\n",
            "\toptimizer: sgd\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 6.534241698714155e-05\n",
            "2025-10-25 14:54:21,646 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=tanh --autoaugment=False --batch_size=128 --epochs=100 --lr=0.11337537084409292 --optimizer=sgd --scheduler=cosine --seed=42 --weight_decay=6.534241698714155e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_145425-e9r3epkr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexalted-sweep-21\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/e9r3epkr\u001b[0m\n",
            "2025-10-25 14:54:26,652 - wandb.wandb_agent - INFO - Running runs: ['e9r3epkr']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/100:   0% 0/352 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100:  28% 100/352 [00:04<00:15, 16.51it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.7759\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-e9r3epkr-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_1ef61f02e7d0b9e875...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-e9r3epkr-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_35201_1ef61f02e7d0b9e875...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-e9r3epkr-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_35201_1ef61f02e7d0b9e875...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-e9r3epkr-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_35201_1ef61f02e7d0b9e875...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-e9r3epkr-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_35201_1ef61f02e7d0b9e875...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-e9r3epkr-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_35201_1ef61f02e7d0b9e875...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-e9r3epkr-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_35201_1ef61f02e7d0b9e875...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-e9r3epkr-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_1ef61f02e7d0b9e875...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-e9r3epkr-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_1ef61f02e7d0b9e875...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ███████▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▂▂▂▂▂▂▂▃▄▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ▅▅█▄▄▆▄▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▁▃▂▂▃▃▃▄▄▃▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▅▅▆▇▅▇▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.7759\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.63347\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.76829\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.65175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.74\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.71934\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mexalted-sweep-21\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/e9r3epkr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_145425-e9r3epkr/logs\u001b[0m\n",
            "2025-10-25 15:32:55,428 - wandb.wandb_agent - INFO - Cleaning up finished run: e9r3epkr\n",
            "2025-10-25 15:32:55,841 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 15:32:55,841 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: gelu\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 128\n",
            "\tepochs: 100\n",
            "\tlr: 0.19954667376446145\n",
            "\toptimizer: sgd\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.0008413627667228198\n",
            "2025-10-25 15:32:55,843 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=gelu --autoaugment=True --batch_size=128 --epochs=100 --lr=0.19954667376446145 --optimizer=sgd --scheduler=cosine --seed=42 --weight_decay=0.0008413627667228198\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_153259-dah143bm\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwhole-sweep-22\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/dah143bm\u001b[0m\n",
            "2025-10-25 15:33:00,848 - wandb.wandb_agent - INFO - Running runs: ['dah143bm']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/100:   0% 0/352 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100:  28% 99/352 [00:05<00:11, 21.63it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.9057\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_24ccb2a48e2a4b2c42...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_35201_24ccb2a48e2a4b2c42...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_35201_24ccb2a48e2a4b2c42...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_35201_24ccb2a48e2a4b2c42...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_35201_24ccb2a48e2a4b2c42...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_35201_24ccb2a48e2a4b2c42...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_35201_24ccb2a48e2a4b2c42...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_24ccb2a48e2a4b2c42...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_24ccb2a48e2a4b2c42...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-dah143bm-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ██████▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▃▄▄▄▅▃▅▅▅▅▅▅▆▆▆▅▅▆▆▆▆▅▆▆▇▆▆▇▇▇▇▇▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ▇█▅▆▆▅▅▆▄▅▅▅▄▅▄▄▄▄▄▄▃▄▃▃▃▃▄▃▃▃▃▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▁▃▃▂▄▄▄▄▄▄▅▅▅▅▅▅▆▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▇▅▇▄▄▄▄▅▅▅▅▄▄▄▅▄▄▃▃▃▄▃▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.9057\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.28626\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.89269\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.32087\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.8556\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.42637\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mwhole-sweep-22\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/dah143bm\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_153259-dah143bm/logs\u001b[0m\n",
            "2025-10-25 16:34:20,333 - wandb.wandb_agent - INFO - Cleaning up finished run: dah143bm\n",
            "2025-10-25 16:34:20,848 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 16:34:20,848 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: gelu\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 128\n",
            "\tepochs: 50\n",
            "\tlr: 0.062314153899416115\n",
            "\toptimizer: sgd\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.0005133139590950919\n",
            "2025-10-25 16:34:20,849 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=gelu --autoaugment=True --batch_size=128 --epochs=50 --lr=0.062314153899416115 --optimizer=sgd --scheduler=cosine --seed=42 --weight_decay=0.0005133139590950919\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_163424-lmm2it9v\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mconfused-sweep-23\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/lmm2it9v\u001b[0m\n",
            "2025-10-25 16:34:25,855 - wandb.wandb_agent - INFO - Running runs: ['lmm2it9v']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/50:   0% 0/352 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/50:  28% 99/352 [00:05<00:11, 21.44it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.9289\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e521aeece00224e30b...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e521aeece00224e30b...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e521aeece00224e30b...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e521aeece00224e30b...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e521aeece00224e30b...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e521aeece00224e30b...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e521aeece00224e30b...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e521aeece00224e30b...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.5s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_17601_e521aeece00224e30b...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-lmm2it9v-val_acc_vs_step_table (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▃▄▅▅▅▅▅▅▆▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▆▆▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▂▄▄▅▅▅▆▅▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇███████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▇▆▅▄▄▄▃▄▃▃▃▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.9289\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.22371\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.92251\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.22562\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.875\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.3747\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mconfused-sweep-23\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/lmm2it9v\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_163424-lmm2it9v/logs\u001b[0m\n",
            "2025-10-25 17:05:13,383 - wandb.wandb_agent - INFO - Cleaning up finished run: lmm2it9v\n",
            "2025-10-25 17:05:13,761 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 17:05:13,761 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: gelu\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 128\n",
            "\tepochs: 100\n",
            "\tlr: 0.16546978813754132\n",
            "\toptimizer: sgd\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.00034212899463822354\n",
            "2025-10-25 17:05:13,763 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=gelu --autoaugment=True --batch_size=128 --epochs=100 --lr=0.16546978813754132 --optimizer=sgd --scheduler=cosine --seed=42 --weight_decay=0.00034212899463822354\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_170517-px3yvsyk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlively-sweep-24\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/px3yvsyk\u001b[0m\n",
            "2025-10-25 17:05:18,768 - wandb.wandb_agent - INFO - Running runs: ['px3yvsyk']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/100:   0% 0/352 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100:  28% 99/352 [00:05<00:12, 19.52it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.9300\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-px3yvsyk-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_2f64b2db3b401cbe77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-px3yvsyk-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_35201_2f64b2db3b401cbe77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-px3yvsyk-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_35201_2f64b2db3b401cbe77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-px3yvsyk-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_35201_2f64b2db3b401cbe77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-px3yvsyk-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_35201_2f64b2db3b401cbe77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-px3yvsyk-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_35201_2f64b2db3b401cbe77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-px3yvsyk-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_35201_2f64b2db3b401cbe77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-px3yvsyk-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_2f64b2db3b401cbe77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-px3yvsyk-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_35201_2f64b2db3b401cbe77...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ██████████▇▇▇▇▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▄▅▅▅▅▅▅▆▅▆▆▆▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▅▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇███████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▆▆▄▄▃▃▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.93\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.21634\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.93969\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.1797\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.889\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.33549\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlively-sweep-24\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/px3yvsyk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_170517-px3yvsyk/logs\u001b[0m\n",
            "2025-10-25 18:06:07,315 - wandb.wandb_agent - INFO - Cleaning up finished run: px3yvsyk\n",
            "2025-10-25 18:06:07,657 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 18:06:07,657 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: tanh\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 128\n",
            "\tepochs: 50\n",
            "\tlr: 0.0821299337329335\n",
            "\toptimizer: sgd_nesterov\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.0007016032901052265\n",
            "2025-10-25 18:06:07,658 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=tanh --autoaugment=True --batch_size=128 --epochs=50 --lr=0.0821299337329335 --optimizer=sgd_nesterov --scheduler=cosine --seed=42 --weight_decay=0.0007016032901052265\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_180611-l4hl19gy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33miconic-sweep-25\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/l4hl19gy\u001b[0m\n",
            "2025-10-25 18:06:12,664 - wandb.wandb_agent - INFO - Running runs: ['l4hl19gy']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/50:   0% 0/352 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/50:  28% 100/352 [00:05<00:22, 11.04it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.8476\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-l4hl19gy-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_17601_beae610d1afe814244...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-l4hl19gy-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_17601_beae610d1afe814244...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-l4hl19gy-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_17601_beae610d1afe814244...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-l4hl19gy-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_17601_beae610d1afe814244...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-l4hl19gy-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_17601_beae610d1afe814244...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-l4hl19gy-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_17601_beae610d1afe814244...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-l4hl19gy-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_17601_beae610d1afe814244...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-l4hl19gy-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_17601_beae610d1afe814244...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-l4hl19gy-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_17601_beae610d1afe814244...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ███████▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▁▂▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇█████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ▅▅█▅▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▂▁▂▃▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ▅▅█▅▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.8476\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.43998\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.79816\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.58804\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.7836\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.63689\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33miconic-sweep-25\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/l4hl19gy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_180611-l4hl19gy/logs\u001b[0m\n",
            "2025-10-25 18:37:00,143 - wandb.wandb_agent - INFO - Cleaning up finished run: l4hl19gy\n",
            "2025-10-25 18:37:00,701 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 18:37:00,701 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: gelu\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 64\n",
            "\tepochs: 100\n",
            "\tlr: 0.05928592025520963\n",
            "\toptimizer: sgd\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.000563767147622153\n",
            "2025-10-25 18:37:00,702 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=gelu --autoaugment=True --batch_size=64 --epochs=100 --lr=0.05928592025520963 --optimizer=sgd --scheduler=cosine --seed=42 --weight_decay=0.000563767147622153\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_183704-bjp218rb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexalted-sweep-26\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/bjp218rb\u001b[0m\n",
            "2025-10-25 18:37:05,708 - wandb.wandb_agent - INFO - Running runs: ['bjp218rb']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/100:   0% 0/704 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100:  14% 97/704 [00:03<00:15, 39.61it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[FINAL] Test accuracy: 0.9303\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-bjp218rb-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_70401_3a5a656d5fcffd2b6d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-bjp218rb-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/val_acc_vs_step_table_70401_3a5a656d5fcffd2b6d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-bjp218rb-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/val_acc_vs_step_table_70401_3a5a656d5fcffd2b6d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-bjp218rb-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/val_acc_vs_step_table_70401_3a5a656d5fcffd2b6d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-bjp218rb-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/val_acc_vs_step_table_70401_3a5a656d5fcffd2b6d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-bjp218rb-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/val_acc_vs_step_table_70401_3a5a656d5fcffd2b6d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-bjp218rb-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/val_acc_vs_step_table_70401_3a5a656d5fcffd2b6d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-bjp218rb-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/val_acc_vs_step_table_70401_3a5a656d5fcffd2b6d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-bjp218rb-val_acc_vs_step_table (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/val_acc_vs_step_table_70401_3a5a656d5fcffd2b6d...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading history steps 99-101, summary, console lines 7-7 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading history steps 99-101, summary, console lines 7-7 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading history steps 99-101, summary, console lines 7-7 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr █████████▇▇▇▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▄▂▅▄▅▅▅▅▅▅▆▆▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇█████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▅▅▅▆▆▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▆▇▆▅▅▅▅▄▅▅▄▄▄▄▅▅▃▃▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test_acc 0.9303\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 0.21699\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.93356\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.19216\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.8884\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 0.33903\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mexalted-sweep-26\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/bjp218rb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251025_183704-bjp218rb/logs\u001b[0m\n",
            "2025-10-25 19:40:07,830 - wandb.wandb_agent - INFO - Cleaning up finished run: bjp218rb\n",
            "2025-10-25 19:40:08,248 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2025-10-25 19:40:08,248 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tactivation: tanh\n",
            "\tautoaugment: True\n",
            "\tbatch_size: 64\n",
            "\tepochs: 100\n",
            "\tlr: 0.0730197982005185\n",
            "\toptimizer: sgd_nesterov\n",
            "\tscheduler: cosine\n",
            "\tseed: 42\n",
            "\tweight_decay: 0.0001078008112811859\n",
            "2025-10-25 19:40:08,249 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python Train.py --activation=tanh --autoaugment=True --batch_size=64 --epochs=100 --lr=0.0730197982005185 --optimizer=sgd_nesterov --scheduler=cosine --seed=42 --weight_decay=0.0001078008112811859\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahee-velu\u001b[0m (\u001b[33mmahee-velu-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'cs6886-vgg6-cifar10' when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/CS6886W_CS24M523_A1/wandb/run-20251025_194012-0y4wi53u\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mswept-sweep-27\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/sweeps/efhuc9f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mahee-velu-iitm/sweep-full/runs/0y4wi53u\u001b[0m\n",
            "2025-10-25 19:40:13,255 - wandb.wandb_agent - INFO - Running runs: ['0y4wi53u']\n",
            "/content/CS6886W_CS24M523_A1/Train.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "Epoch 1/100:   0% 0/704 [00:00<?, ?it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/100:  14% 98/704 [00:03<00:14, 41.10it/s]/content/CS6886W_CS24M523_A1/Train.py:120: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        }
      ]
    }
  ]
}